---
title: "CompMus project"
author: "Rachel van 't Hull"
date: "2/10/2021"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
    storyboard: true
---


```{r setup, include=FALSE}
library(readr)
library(leaflet)
library(DT)
library(lubridate)
library(flexdashboard)
library(tidyverse)
library(spotifyr)
library(ggrepel)
library(grid)
library(plotly)
library(compmus)
library(gridExtra)
```

```{r}

pablo_honey <- get_playlist_audio_features("", "1S7Bn1zPkqKler2p1MmE2B")
the_bends <- get_playlist_audio_features("", "00aSCr8pdsbOQvmcj41q6z")
ok_computer <- get_playlist_audio_features("", "6yPwcbgFAUXfSsKD9LPnj8")
kid_a <- get_playlist_audio_features("", "0H7oSmnVe8kctcTbr6hYda")
amnesiac <- get_playlist_audio_features("", "7fuj13FdVe98ZPIo9BBWGj")
hail_to_the_thief <- get_playlist_audio_features("", "3GvfHR5ZF5OqeX5YdwCsIQ")
in_rainbows <- get_playlist_audio_features("", "7eV9P6cpSRyYKuLegRNbbe")
the_king_of_limbs <- get_playlist_audio_features("", "2701aFzj6VyyBuSXNo7DfD")
a_moon_shaped_pool <- get_playlist_audio_features("", "0hlGldKBhW9PosAEdFylRJ")

radiohead <-
  bind_rows(
    pablo_honey %>% mutate(category = "Pablo Honey"),
    the_bends %>% mutate(category = "The Bends"),
    ok_computer %>% mutate(category = "OK Computer"),
    kid_a %>% mutate(category = "Kid A"),
    amnesiac %>% mutate(category = "Amnesiac"),
    hail_to_the_thief %>% mutate(category = "Hail To The Thief"),
    in_rainbows %>% mutate(category = "In Rainbows"),
    the_king_of_limbs %>% mutate(category = "The King Of Limbs"),
    a_moon_shaped_pool %>% mutate(category = "A Moon Shaped Pool")
  )

level_order <- c("Pablo Honey", "The Bends", "OK Computer", "Kid A", "Amnesiac", "Hail To The Thief", "In Rainbows", "The King Of Limbs", "A Moon Shaped Pool")

test <- radiohead %>%
    group_by(playlist_name) %>%
    summarize(meanEnergy = mean(energy), meanValence = mean(valence), meanLoudness = mean((loudness-min(loudness))/(max(loudness)-min(loudness))), meanTempo = mean((tempo-min(tempo))/(max(tempo)-min(tempo))))

test2 <- radiohead %>%
    group_by(playlist_name) %>%
    summarize(meanEnergy = mean(energy), meanValence = mean(valence), meanLoudness = mean(loudness), meanTempo = mean(tempo))
```


```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )
```

### Lowest versus highest energy

```{r}
glass_eyes <- get_tidy_audio_analysis("0uOeAmfdyaekD2RIGwCDwq")
bodysnatchers <- get_tidy_audio_analysis("4pWIwnnqx8k01fuF95UMIg")
```

```{r, echo = FALSE, message = FALSE, figures-side, fig.show="hold", out.width="50%"}

glass_eyes %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

bodysnatchers %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

***
According to the Spotify API, *Glass Eyes* is Radiohead's least energetic song with a recorded energy of 0.110, and *Bodysnatchers* is the band's most energetic song with an energy of 0.976.

The tempogram of *Glass Eyes* shows that the song's tempo is very inconsistent. When listening to the song, it becomes clear why: the song is free of any percussion, and mostly made up of a calm piano melody that was most likely played without following a metronome/tempo (and rather on intuition). This makes the song very hard to tap to, as there appears to be no real tempo even though the Spotify API records a tempo of about 114 BPM. Not being able to detect a tempo in addition to the sad sounding melody makes the song sound even less energetic.

For *Bodysnatchers* however, the complete opposite holds. The tempo is very clear and steady, and also quite high. Whereas the Spotify API records a tempo of about 167 BPM, the tempogram displays a very clear line at two times this tempo (334 BPM). In fact, the tempogram does not show anything at the actual tempo of 167 BPM. In any case, the clear, steady and high tempo of the song make it very energetic.



### (NEW) What makes an album happy/sad?

```{r}
first <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "1S7Bn1zPkqKler2p1MmE2B"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
last <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "0hlGldKBhW9PosAEdFylRJ"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()

happy <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "7eV9P6cpSRyYKuLegRNbbe"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
sad <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "0hlGldKBhW9PosAEdFylRJ"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()

compare1 <-
  first %>%
  mutate(genre = "Pablo Honey") %>%
  bind_rows(last %>% mutate(genre = "A Moon Shaped Pool"))

compare2 <-
  happy %>%
  mutate(genre = "In Rainbows") %>%
  bind_rows(sad %>% mutate(genre = "A Moon Shaped Pool"))
```

```{r}
compare2 %>%
  mutate(
    timbre =
      map(
        segments,
        compmus_summarise,
        timbre,
        method = "mean"
      )
  ) %>%
  select(genre, timbre) %>%
  compmus_gather_timbre() %>%
  ggplot(aes(x = basis, y = value, fill = genre)) +
  geom_violin() +
  scale_fill_viridis_d() +
    ylim(-55, 50) +

  labs(x = "Spotify Timbre Coefficients", y = "", fill = "Album")
```

***
As *A Moon Shaped Pool* is often viewed as the saddest Radiohead album and *In Rainbows* as the happiest, looking at the timbre coefficients might be an interesting way of determining what captures the albums' moods. From the plot shown here, it's clear that the albums significantly differ in distribution of the first coefficient, with *A Moon Shaped Pool* containing lower values. This makes sense as this coefficient is associated with loudness: sad music is most likely to be more quiet than happy music. For the rest of the coefficients, the values are either alike or the meaning of the coefficient is unclear.

### Introduction
Rachel van 't Hull - 12179299

The corpus I chose contains all 101 songs from Radiohead's 9 studio albums, that is *Pablo Honey*, *The Bends*, *OK Computer*, *Kid A*, *Amnesiac*, *Hail to the Thief*, *In Rainbows*, *The King of Limbs* and *A Moon Shaped Pool*. While all of Radiohead's albums can be labeled as rock, the band has experimented with different sounds along the way, making each individual album to contain a distinct sound in terms of instruments, style and theme, which makes the corpus very fit for a computational musicological research.

Though each album carries a distinct feel, the songs within an album often range from quiet to grunge. For example, perhaps Radiohead's most famous song, *Creep*, has a very different sound from the rest of grunge album *Pablo Honey*. For *The Bends*, whereas *Fake Plastic Trees* is a soft and calm song, *My Iron Lung* returns to hard-rock sounds. On the other hand, *Paranoid Android* is very typical for *OK Computer*, containing the "sci-fi" sounds present throughout the album. Furthermore, while most albums are made in different phases of the band's style, the album *Amnesiac* in general has very similar sounds to *Kid A* as they were recorded during the same sessions.

The variation in both Radiohead's different albums as well as the individual songs within an album makes it interesting to not only analyze how Radiohead's style has evolved over time, but also see whether a computational model regards songs from different albums as similar. For both these questions, the factors contributing to the outcomes could be very interesting in describing Radiohead's different sounds within its discography in a computational, musicological manner.

### Repitition and structure in Radiohead's most famous songs

```{r}
creep <-
  get_tidy_audio_analysis("70LcF31zb1H0PyJoS1Sx1r") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
```

```{r}
fake_plastic_trees <-
  get_tidy_audio_analysis("73CKjW3vsUXRpy3NnX4H7F") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )
```

```{r}
creep_timbre <-
  creep %>%
    compmus_self_similarity(timbre, "cosine") %>% 
    ggplot(
      aes(
        x = xstart + xduration / 2,
        width = xduration,
        y = ystart + yduration / 2,
        height = yduration,
        fill = d
      )
    ) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(guide = "none") +
    theme_classic() +
    labs(x = NULL, y = "Timbre") +
    scale_x_continuous(
      breaks = c(20, 61, 82, 123, 145, 186, 208),
      labels =
        c("Verse",
          "Chorus",
          "Verse",
          "Chorus",
          "Bridge",
          "Verse",
          "Chorus"
        ),
    ) +
  theme(
        axis.text.x = element_text(angle=90, hjust="1")
  )
```

```{r}
creep_chroma <-
  creep %>%
    compmus_self_similarity(pitches, "angular") %>% 
    ggplot(
      aes(
        x = xstart + xduration / 2,
        width = xduration,
        y = ystart + yduration / 2,
        height = yduration,
        fill = d
      )
    ) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(guide = "none") +
    theme_classic() +
    labs(x = NULL, y = "Chroma",  title = "Creep") +
     theme(plot.title = element_text(hjust = 0.5))
```

```{r}
fake_plastic_trees_timbre <-
  fake_plastic_trees %>%
    compmus_self_similarity(timbre, "cosine") %>% 
    ggplot(
      aes(
        x = xstart + xduration / 2,
        width = xduration,
        y = ystart + yduration / 2,
        height = yduration,
        fill = d
      )
    ) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(guide = "none") +
    theme_classic() +
    labs(x = NULL, y = NULL) +
    theme(plot.title = element_text(hjust = 0.5)) +
      scale_x_continuous(
      breaks = c(0, 50, 78, 130, 157, 207, 233),
      labels =
        c("Verse",
          "Chorus",
          "Verse",
          "Chorus",
          "Bridge",
          "Chorus",
          "Outro"
        ),
    ) +
  theme(
        axis.text.x = element_text(angle=90, hjust="1")
  )
```

```{r}
fake_plastic_trees_chroma <-
  fake_plastic_trees %>%
    compmus_self_similarity(pitches, "cosine") %>% 
    ggplot(
      aes(
        x = xstart + xduration / 2,
        width = xduration,
        y = ystart + yduration / 2,
        height = yduration,
        fill = d
      )
    ) +
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(guide = "none") +
    theme_classic() +
    labs(x = NULL, y = NULL, title = "Fake Plastic Trees") +
     theme(plot.title = element_text(hjust = 0.5))
```

```{r}
grid.arrange(creep_chroma, fake_plastic_trees_chroma, creep_timbre, fake_plastic_trees_timbre, ncol=2, nrow=2, widths = c(2,2) , heights = c(2,2))
```

***
Two of Radiohead's most famous songs are *Creep* and *Fake Plastic Trees*. The reason that these songs are well-liked might be due to their repitition. *Creep* has one melody that's repeated throughout the entire song, except for in the bridge. *Fake Plastic trees* has one verse melody and one chorus melody, with a "bridge" that has the same melody as the verses but is played and sung in a different manner.

When looking at *Creep*'s chroma-based self-similarity matrix, it is very clear that the same melody is repeated over and over again, with a transition between each repetition. From the timbre-based self-similarity matrix, the structure of the song is very clear.

For *Fake Plastic Trees*, the chroma-based self-similarity matrix is a lot less structured. Some bits of repitition can be discovered from where the choruses are, but overall it is very chaotic and hard to analyze. The timbre-based self-similarity matrix is a lot clearer, and the structure of the song is nicely captured.

It's remarkable that the chroma-based self-similarity matrix for *Fake Platic Trees* is so unclear compared to that of *Creep*, as both have a repeating melody.



### Comparing the albums 1

```{r}
line_plot <- ggplot(test, aes(x=factor(playlist_name, level=level_order), group = 1)) + 
  geom_line(aes(y = meanValence, colour = "Valence", group=1, label="Test")) + 
  geom_line(aes(y = meanEnergy, colour="Energy", group=2)) +
  geom_line(aes(y= meanLoudness, colour="Loudness", group=3)) +
  geom_line(aes(y= meanTempo, colour="Tempo", group=4)) +
  scale_colour_manual("", 
                      breaks = c("Valence", "Energy", "Loudness", "Tempo"),
                      values = c("red", "green", "steelblue", "purple"))+
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1)) +
  scale_x_discrete(guide = guide_axis(n.dodge=2)) +
  theme(axis.text.x = element_text(size = 7)) +
    labs(
    title = "Valence, Energy, Loudness and Tempo per Album",
    x = "Album",
    y = "Values"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(angle=30, hjust="1")
  )

ggplotly(line_plot)
```

***
For this visualisation, the loudness and tempo of the songs were normalized.
Valence and energy seem to follow almost exactly the same trend throughout the albums: a fall from *Pablo Honey* until *Amnesiac*, followed by a rise until *The King Of Limbs*, to fall again in *A Moon Shaped Pool*. loudness also follows this pattern from *Kid A* onwards, but at first rises from *Pablo Honey* until *Kid A*.

Tempo differs from the other trends the most. What is especially striking is that while energy falls from *Pablo Honey* until *Amnesiac*, the tempo rises. The opposite holds from the change between *Amnesiac* and *Hail To The Thief* and the change between *The King Of Limbs* and *A Moon Shaped Pool*.
Only from *Hail To The Thief* until *The King Of Limbs*, all 4 variables align.


### Comparing the albums 2

```{r}
per_album <- ggplot(test2, aes(x = meanValence, y = meanEnergy, size = meanLoudness, color = meanTempo, label=playlist_name)) +  
  geom_point(show.legend = T, alpha=0.8) +
    scale_size_continuous(      # Fine-tune the sizes of each point.
    trans = "exp",            # Use an exp transformation to emphasise loud.
  ) +
  scale_color_continuous(      # Fine-tune the sizes of each point.
    trans = "exp"            # Use an exp transformation to emphasise loud.
  ) +
  scale_colour_gradient(low="#A9C8F3", high="#0C2389") +
  geom_text_repel(aes(label=playlist_name),  size=3, color="black") +
  labs(
    title = "Mean Valence, Energy, Loudness and Tempo per Album",
    x = "Valence",
    y = "Energy"
  ) +
  theme(plot.title = element_text(hjust = 0.5))

ggplotly(per_album)
  
```


***
The saddest album appears to be the band's most recent album, *A Moon Shaped Pool*, clearly having both the lowest valence as well as the lowest energy, and also being the second most quiet. *The King Of Limbs*, seems to be the happiest album, being the highest in valence and the second highest in energy.

Furthermore, *Hail To The Thief* and *In Rainbows* are almost exactly the same concerning valence, energy, with loudness only differing a tiny bit. *In Rainbows* being the album that followed up *Hail To The Thief* could be the explanation for this, however the albums are more than 4 years apart.

While most albums are some distance apart in the graph, the maximum and minimum values of valence and energy are only about 0.30 and 0.25 apart, respectively. To make more meaningful claims about the differences between individual albums, the songs in each album are to be taken into account.


### Comparing individual songs

```{r}
all_songs <- ggplot(radiohead, aes(x = valence, y = energy, size = loudness, color = factor(playlist_name, level = level_order), label = track.name)) +  
  geom_point(show.legend = T, alpha=0.8) +
    scale_size_continuous(      # Fine-tune the sizes of each point.
    trans = "exp",            # Use an exp transformation to emphasise loud.
  ) +
  labs(
    title = "Mean Valence, Energy, Loudness and Tempo per Album",
    x = "Valence",
    y = "Energy"
  ) +
  theme_light()+
  theme(plot.title = element_text(hjust = 0.5))
  
ggplotly(all_songs)
```



### Comparing songs within each album

```{r}
songs_albums <- radiohead %>%
  ggplot(
    aes(x = valence, 
        y = energy,
        size = loudness,
        color = tempo,
        label = track.name
    )
  ) +
  geom_point(alpha=0.8,  show.legend = T) +
    facet_wrap(~factor(playlist_name, level=level_order)) +     # Separate charts per playlist.
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 0.85),
    breaks = c(0, 0.50, 1)   # Use grid-lines for quadrants only.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1.1),
    breaks = c(0, 0.50, 1)
  ) +
  scale_size_continuous(      # Fine-tune the sizes of each point.
    trans = "exp",            # Use an exp transformation to emphasise loud.
  ) +
    labs(
    title = "Valence, Energy, Loudness and Tempo per Album",
    x = "Valence",
    y = "Energy"
  ) +
  theme(plot.title = element_text(hjust = 0.5)) +
 scale_colour_gradient(low="#A9C8F3", high="#0C2389")

ggplotly(songs_albums)
```

***
Most songs within an album are somewhat centered around one or two points of energy and valence (especially around low valence and medium energy), some more obvious than others. Exceptions are *Hail To The Thief* and *The King Of Limbs*, where energy and valence differ most throughout each individual song.


### Happiest song


```{r}
step <-
  get_tidy_audio_analysis("4oXg7xT4ksBxHTx8PcmSXw") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

step %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() +
    scale_x_continuous(
    breaks = c(9, 19, 40, 74, 99, 117, 142, 189, 204),
    labels =
      c("Vocals set in",
        "Percussion only",
        "Guitar riff added",
        "Bass guitar added",
        "Interlude",
        "Verse",
        "Interlude",
        "Chorus",
        "Outro"
      ),
  ) +
  theme(
        axis.text.x = element_text(angle=90, hjust="1")
  )
```

*** 
Previous visualizations, suggest that *15 Steps* is the "happiest" radiohead song when considering valence and energy. To further look into what makes the song sound relatively happy, we can look into the chromatic features of the song using a chromagram. The chromagram pictured here uses a Euclidean norm. (I don't really have anything useful to say about the chromagrams yet.)

### Saddest song

```{r}
true_love_waits <-
  get_tidy_audio_analysis("07XaOyTS5hyaWiUK1Bc3bR") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

true_love_waits %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() +
  scale_x_continuous(
    breaks = c(0, 9, 61, 77, 84, 106, 142,149, 179, 232, 250),
    labels =
      c("Piano melody",
        "Vocals set in",
        "Chorus",
        "Extra instruments",
        "Verse",
        "Extra piano melody added",
        "Sounds added",
        "Chorus",
        "Verse",
        "Chorus",
        "Outro"
      ),
  ) +
  theme(
        axis.text.x = element_text(angle=90, hjust="1")
  )
```

***
Whereas *15 Steps* is the happiest song, *True Love Waits* is the saddest according to its energy and valence values. The chromagram pictured here uses a Euclidean norm.